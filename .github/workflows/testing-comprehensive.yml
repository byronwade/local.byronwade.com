name: 🧪 Comprehensive Testing Strategy

on:
  push:
    branches: [main, develop, feature/*, hotfix/*]
  pull_request:
    branches: [main, develop]
  schedule:
    - cron: '0 4 * * 1-5' # Weekdays at 4 AM UTC for regression testing
  workflow_dispatch:
    inputs:
      test_type:
        description: 'Type of test to run'
        required: true
        default: 'all'
        type: choice
        options:
          - all
          - unit
          - integration
          - e2e
          - performance
          - chaos
          - regression

concurrency:
  group: testing-${{ github.ref }}-${{ github.event.inputs.test_type || 'all' }}
  cancel-in-progress: true

env:
  NODE_VERSION: '20'
  BUN_VERSION: 'latest'
  CI: true

jobs:
  # Test Configuration Matrix
  test-matrix:
    name: 🎯 Test Strategy Matrix
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.set-matrix.outputs.matrix }}
    steps:
      - name: Set Test Matrix
        id: set-matrix
        run: |
          case "${{ github.event.inputs.test_type || 'all' }}" in
            "unit")
              matrix='{"include":[{"type":"unit","name":"Unit Tests","command":"test:unit"}]}'
              ;;
            "integration")
              matrix='{"include":[{"type":"integration","name":"Integration Tests","command":"test:integration"}]}'
              ;;
            "e2e")
              matrix='{"include":[{"type":"e2e","name":"E2E Tests","command":"test:e2e"}]}'
              ;;
            "performance")
              matrix='{"include":[{"type":"performance","name":"Performance Tests","command":"test:performance"}]}'
              ;;
            "chaos")
              matrix='{"include":[{"type":"chaos","name":"Chaos Tests","command":"test:chaos"}]}'
              ;;
            *)
              matrix='{"include":[
                {"type":"unit","name":"Unit Tests","command":"test:unit"},
                {"type":"integration","name":"Integration Tests","command":"test:integration"},
                {"type":"component","name":"Component Tests","command":"test:component"},
                {"type":"api","name":"API Tests","command":"test:api"},
                {"type":"e2e","name":"E2E Tests","command":"test:e2e"}
              ]}'
              ;;
          esac
          echo "matrix=$matrix" >> $GITHUB_OUTPUT

  # Unit Tests with Multiple Test Runners
  unit-tests:
    name: 🔬 ${{ matrix.name }}
    runs-on: ubuntu-latest
    needs: test-matrix
    if: contains(fromJson(needs.test-matrix.outputs.matrix).include[*].type, 'unit') || github.event.inputs.test_type == 'all' || github.event.inputs.test_type == 'unit'
    strategy:
      fail-fast: false
      matrix:
        test-runner: [vitest, jest]
        shard: [1, 2, 3, 4] # Parallel test execution
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Bun
        uses: oven-sh/setup-bun@v1
        with:
          bun-version: ${{ env.BUN_VERSION }}

      - name: Cache dependencies
        uses: actions/cache@v3
        with:
          path: ~/.bun/install/cache
          key: ${{ runner.os }}-bun-${{ hashFiles('**/bun.lockb') }}

      - name: Install dependencies
        run: bun install --frozen-lockfile

      - name: Run Unit Tests - ${{ matrix.test-runner }}
        run: |
          case "${{ matrix.test-runner }}" in
            "vitest")
              bun run test:unit --shard=${{ matrix.shard }}/4 --coverage --reporter=junit
              ;;
            "jest")
              bun run test:unit:jest --shard=${{ matrix.shard }}/4 --coverage --ci
              ;;
          esac
        env:
          NODE_ENV: test

      - name: Upload Test Results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: unit-test-results-${{ matrix.test-runner }}-${{ matrix.shard }}
          path: |
            coverage/
            test-results/
            junit.xml

      - name: Publish Test Results
        uses: dorny/test-reporter@v1
        if: success() || failure()
        with:
          name: Unit Tests (${{ matrix.test-runner }}-${{ matrix.shard }})
          path: junit.xml
          reporter: jest-junit

  # Integration Tests
  integration-tests:
    name: 🔗 Integration Tests
    runs-on: ubuntu-latest
    needs: test-matrix
    if: contains(fromJson(needs.test-matrix.outputs.matrix).include[*].type, 'integration') || github.event.inputs.test_type == 'all' || github.event.inputs.test_type == 'integration'
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: thorbis_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

      redis:
        image: redis:7
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Bun
        uses: oven-sh/setup-bun@v1
        with:
          bun-version: ${{ env.BUN_VERSION }}

      - name: Install dependencies
        run: bun install --frozen-lockfile

      - name: Setup Test Database
        run: |
          bun run db:migrate:test
          bun run db:seed:test
        env:
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/thorbis_test

      - name: Run Integration Tests
        run: bun run test:integration --coverage
        env:
          NODE_ENV: test
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/thorbis_test
          REDIS_URL: redis://localhost:6379

      - name: Upload Integration Test Results
        uses: actions/upload-artifact@v4
        with:
          name: integration-test-results
          path: |
            coverage/
            test-results/

  # Component Testing (React Testing Library + Storybook)
  component-tests:
    name: 🧩 Component Tests
    runs-on: ubuntu-latest
    needs: test-matrix
    if: contains(fromJson(needs.test-matrix.outputs.matrix).include[*].type, 'component') || github.event.inputs.test_type == 'all'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Bun
        uses: oven-sh/setup-bun@v1
        with:
          bun-version: ${{ env.BUN_VERSION }}

      - name: Install dependencies
        run: bun install --frozen-lockfile

      - name: Build Storybook
        run: bun run build-storybook

      - name: Run Component Tests
        run: bun run test:component --coverage

      - name: Visual Regression Tests (Chromatic)
        uses: chromaui/action@v1
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          projectToken: ${{ secrets.CHROMATIC_PROJECT_TOKEN }}
          buildScriptName: build-storybook

      - name: Upload Component Test Results
        uses: actions/upload-artifact@v4
        with:
          name: component-test-results
          path: |
            coverage/
            storybook-static/

  # API Testing
  api-tests:
    name: 🔌 API Tests
    runs-on: ubuntu-latest
    needs: test-matrix
    if: contains(fromJson(needs.test-matrix.outputs.matrix).include[*].type, 'api') || github.event.inputs.test_type == 'all'
    strategy:
      matrix:
        environment: [staging, mock]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Bun
        uses: oven-sh/setup-bun@v1
        with:
          bun-version: ${{ env.BUN_VERSION }}

      - name: Install dependencies
        run: bun install --frozen-lockfile

      - name: Start Application (Mock Environment)
        if: matrix.environment == 'mock'
        run: |
          bun run build
          bun run start &
          sleep 10
        env:
          NODE_ENV: test
          NEXT_PUBLIC_API_URL: http://localhost:3000

      - name: Run API Tests with Newman (Postman)
        run: |
          bun add -g newman
          newman run tests/api/postman-collection.json \
            --environment tests/api/environments/${{ matrix.environment }}.json \
            --reporters cli,json \
            --reporter-json-export api-test-results.json

      - name: Run API Tests with Supertest
        run: bun run test:api:supertest
        env:
          NODE_ENV: test
          API_BASE_URL: ${{ matrix.environment == 'staging' && secrets.STAGING_API_URL || 'http://localhost:3000' }}

      - name: Upload API Test Results
        uses: actions/upload-artifact@v4
        with:
          name: api-test-results-${{ matrix.environment }}
          path: |
            api-test-results.json
            test-results/

  # End-to-End Tests
  e2e-tests:
    name: 🎭 E2E Tests
    runs-on: ubuntu-latest
    needs: test-matrix
    if: contains(fromJson(needs.test-matrix.outputs.matrix).include[*].type, 'e2e') || github.event.inputs.test_type == 'all' || github.event.inputs.test_type == 'e2e'
    strategy:
      fail-fast: false
      matrix:
        browser: [chromium, firefox, webkit]
        shard: [1, 2, 3]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Bun
        uses: oven-sh/setup-bun@v1
        with:
          bun-version: ${{ env.BUN_VERSION }}

      - name: Install dependencies
        run: bun install --frozen-lockfile

      - name: Install Playwright Browsers
        run: bun x playwright install --with-deps ${{ matrix.browser }}

      - name: Build and Start Application
        run: |
          bun run build
          bun run start &
          sleep 15
        env:
          NODE_ENV: production

      - name: Wait for Application
        run: |
          npx wait-on http://localhost:3000 --timeout 60000

      - name: Run E2E Tests
        run: |
          bun x playwright test \
            --browser=${{ matrix.browser }} \
            --shard=${{ matrix.shard }}/3 \
            --reporter=html,junit
        env:
          PLAYWRIGHT_BROWSER: ${{ matrix.browser }}

      - name: Upload E2E Test Results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: e2e-results-${{ matrix.browser }}-${{ matrix.shard }}
          path: |
            playwright-report/
            test-results/
            results.xml

      - name: Publish E2E Test Results
        uses: dorny/test-reporter@v1
        if: success() || failure()
        with:
          name: E2E Tests (${{ matrix.browser }}-${{ matrix.shard }})
          path: results.xml
          reporter: jest-junit

  # Performance Testing
  performance-tests:
    name: ⚡ Performance Tests
    runs-on: ubuntu-latest
    if: github.event.inputs.test_type == 'all' || github.event.inputs.test_type == 'performance'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Bun
        uses: oven-sh/setup-bun@v1
        with:
          bun-version: ${{ env.BUN_VERSION }}

      - name: Install dependencies
        run: bun install --frozen-lockfile

      - name: Build application
        run: bun run build

      - name: Start application
        run: |
          bun run start &
          sleep 15

      # Lighthouse Performance Testing
      - name: Lighthouse Performance Audit
        run: |
          bun add -g @lhci/cli
          lhci autorun --collect.url=http://localhost:3000
        env:
          LHCI_GITHUB_APP_TOKEN: ${{ secrets.LHCI_GITHUB_APP_TOKEN }}

      # Load Testing with Artillery
      - name: Load Testing with Artillery
        run: |
          bun add -g artillery
          artillery run tests/performance/load-test.yml

      # Memory Leak Testing
      - name: Memory Leak Testing
        run: |
          bun add -g clinic
          clinic doctor -- bun run start &
          sleep 30
          pkill -f "bun run start"

      - name: Upload Performance Results
        uses: actions/upload-artifact@v4
        with:
          name: performance-test-results
          path: |
            .lighthouseci/
            artillery-report.html
            clinic-doctor/

  # Chaos Engineering Tests
  chaos-tests:
    name: 🌪️ Chaos Engineering
    runs-on: ubuntu-latest
    if: github.event.inputs.test_type == 'chaos' && github.ref == 'refs/heads/main'
    environment: staging
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Chaos Testing Tools
        run: |
          # Install chaos engineering tools
          curl -s https://api.github.com/repos/chaosblade-io/chaosblade/releases/latest \
            | grep browser_download_url \
            | grep linux-amd64 \
            | cut -d '"' -f 4 \
            | wget -qi -

      - name: Database Connection Chaos Test
        run: |
          # Simulate database connection issues
          echo "Simulating database connection chaos..."
          # Add database chaos testing logic

      - name: Network Latency Chaos Test
        run: |
          # Simulate network latency issues
          echo "Simulating network latency chaos..."
          # Add network chaos testing logic

      - name: Memory Pressure Chaos Test
        run: |
          # Simulate memory pressure
          echo "Simulating memory pressure chaos..."
          # Add memory chaos testing logic

      - name: Upload Chaos Test Results
        uses: actions/upload-artifact@v4
        with:
          name: chaos-test-results
          path: chaos-results/

  # Test Results Aggregation
  test-summary:
    name: 📊 Test Summary Report
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests, component-tests, api-tests, e2e-tests]
    if: always()
    steps:
      - name: Download All Test Artifacts
        uses: actions/download-artifact@v4

      - name: Generate Test Summary Report
        run: |
          echo "# 🧪 Test Execution Summary" >> $GITHUB_STEP_SUMMARY
          echo "## Test Results Overview:" >> $GITHUB_STEP_SUMMARY
          echo "- **Unit Tests**: ${{ needs.unit-tests.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Integration Tests**: ${{ needs.integration-tests.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Component Tests**: ${{ needs.component-tests.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- **API Tests**: ${{ needs.api-tests.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- **E2E Tests**: ${{ needs.e2e-tests.result }}" >> $GITHUB_STEP_SUMMARY

      - name: Test Failure Notification
        if: contains(needs.*.result, 'failure')
        run: |
          curl -X POST "${{ secrets.SLACK_WEBHOOK_URL }}" \
            -H 'Content-type: application/json' \
            --data '{
              "text": "🚨 Tests failed for ${{ github.repository }}",
              "attachments": [{
                "color": "danger",
                "fields": [{
                  "title": "Branch",
                  "value": "${{ github.ref_name }}",
                  "short": true
                }, {
                  "title": "Commit",
                  "value": "${{ github.sha }}",
                  "short": true
                }, {
                  "title": "Failed Tests",
                  "value": "${{ join(needs.*.result, ', ') }}",
                  "short": false
                }]
              }]
            }'

      - name: Coverage Report Aggregation
        run: |
          # Aggregate coverage reports from all test types
          bun add -g nyc
          nyc merge coverage/ .nyc_output/coverage.json
          nyc report --reporter=lcov --reporter=text-summary

      - name: Upload Aggregated Coverage
        uses: codecov/codecov-action@v4
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          file: coverage/lcov.info
          name: aggregated-coverage