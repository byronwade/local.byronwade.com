---
description: USE WHEN planning new features, evolving database schema, or ensuring backwards compatibility during development
---

# Schema Evolution & Feature Development Rules

## üß¨ Database Evolution Philosophy

**The database schema must evolve thoughtfully, maintaining backwards compatibility while supporting new features efficiently.**

## üìã Feature Development Database Checklist

### Before Starting Any New Feature:
```javascript
const featurePrerequisites = {
  // 1. Schema Analysis
  schemaImpact: 'Identify required table/column changes',
  relationships: 'Map data relationships and dependencies', 
  performance: 'Estimate query performance impact',
  
  // 2. Data Lifecycle Planning
  dataRetention: 'Define data retention policies',
  cleanupStrategy: 'Plan automated cleanup procedures',
  archiveStrategy: 'Design archiving approach',
  
  // 3. Migration Strategy
  migrationPlan: 'Create step-by-step migration plan',
  rollbackPlan: 'Design rollback procedures',
  testingPlan: 'Plan comprehensive testing approach',
  
  // 4. Performance Considerations
  indexStrategy: 'Plan required indexes',
  queryOptimization: 'Optimize critical query paths',
  caching: 'Design caching strategy'
};
```

## üèóÔ∏è Schema Evolution Patterns

### Pattern 1: Adding New Features (Zero Downtime)
```sql
-- Phase 1: Add new table/columns (non-breaking)
-- ‚úÖ Safe: Adding nullable columns
ALTER TABLE businesses ADD COLUMN new_feature_data JSONB;
ALTER TABLE businesses ADD COLUMN feature_enabled BOOLEAN DEFAULT false;

-- ‚úÖ Safe: Adding new tables
CREATE TABLE business_features (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    business_id UUID NOT NULL REFERENCES businesses(id) ON DELETE CASCADE,
    feature_type TEXT NOT NULL,
    configuration JSONB DEFAULT '{}',
    enabled BOOLEAN DEFAULT false,
    created_at TIMESTAMPTZ DEFAULT NOW(),
    updated_at TIMESTAMPTZ DEFAULT NOW()
);

-- Phase 2: Update application to use new schema
-- Deploy application code that uses new columns/tables

-- Phase 3: Backfill data (if needed)
UPDATE businesses 
SET feature_enabled = true 
WHERE premium_subscription = true;

-- Phase 4: Add constraints (after data validation)
ALTER TABLE businesses 
ADD CONSTRAINT check_feature_data 
CHECK (new_feature_data IS NULL OR jsonb_typeof(new_feature_data) = 'object');
```

### Pattern 2: Modifying Existing Features (Multi-Step)
```sql
-- Example: Changing business status from TEXT to ENUM

-- Step 1: Create new enum type
CREATE TYPE business_status_enum AS ENUM ('draft', 'published', 'suspended', 'archived');

-- Step 2: Add new column
ALTER TABLE businesses ADD COLUMN status_new business_status_enum;

-- Step 3: Migrate data gradually
UPDATE businesses 
SET status_new = 
    CASE 
        WHEN status = 'active' THEN 'published'::business_status_enum
        WHEN status = 'inactive' THEN 'archived'::business_status_enum
        WHEN status = 'pending' THEN 'draft'::business_status_enum
        ELSE 'draft'::business_status_enum
    END
WHERE status_new IS NULL 
LIMIT 1000;

-- Step 4: Update application to use new column
-- (Deploy application code)

-- Step 5: Drop old column and rename new one
ALTER TABLE businesses DROP COLUMN status;
ALTER TABLE businesses RENAME COLUMN status_new TO status;
```

### Pattern 3: Feature Deprecation (Graceful Removal)
```sql
-- Phase 1: Mark feature as deprecated (add deprecation metadata)
ALTER TABLE deprecated_features ADD COLUMN deprecated_at TIMESTAMPTZ DEFAULT NOW();
ALTER TABLE deprecated_features ADD COLUMN removal_date TIMESTAMPTZ;

-- Phase 2: Stop writing to deprecated tables/columns
-- Update application to stop using deprecated schema

-- Phase 3: Archive deprecated data
INSERT INTO archived_deprecated_features 
SELECT * FROM deprecated_features 
WHERE deprecated_at < NOW() - INTERVAL '90 days';

-- Phase 4: Remove deprecated schema
DROP TABLE deprecated_features;
```

## üéØ Feature-Specific Schema Guidelines

### Analytics Features
```sql
-- Template for new analytics tables
CREATE TABLE {feature_name}_analytics (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    entity_id UUID NOT NULL, -- References the main entity
    date DATE NOT NULL,
    
    -- Metrics (always include created_at for time-series)
    metric_1 INTEGER DEFAULT 0,
    metric_2 INTEGER DEFAULT 0,
    metric_3 DECIMAL(10,2) DEFAULT 0,
    
    -- Metadata for flexibility
    metadata JSONB DEFAULT '{}',
    
    -- Standard timestamps
    created_at TIMESTAMPTZ DEFAULT NOW(),
    
    -- Constraints
    UNIQUE(entity_id, date),
    CHECK (date >= '2024-01-01'::DATE)
);

-- Required indexes for analytics
CREATE INDEX idx_{feature_name}_analytics_entity_date ON {feature_name}_analytics(entity_id, date);
CREATE INDEX idx_{feature_name}_analytics_date ON {feature_name}_analytics(date);

-- Partition by month for large datasets
CREATE TABLE {feature_name}_analytics_y2024m01 PARTITION OF {feature_name}_analytics
FOR VALUES FROM ('2024-01-01') TO ('2024-02-01');
```

### User-Generated Content Features
```sql
-- Template for UGC features
CREATE TABLE {feature_name}_content (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    user_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    
    -- Content fields
    title TEXT NOT NULL,
    content TEXT,
    content_type TEXT DEFAULT 'text',
    
    -- Moderation
    status TEXT DEFAULT 'pending' CHECK (status IN ('pending', 'approved', 'rejected', 'flagged')),
    moderated_by UUID REFERENCES users(id),
    moderated_at TIMESTAMPTZ,
    
    -- SEO and discovery
    slug TEXT UNIQUE,
    tags TEXT[],
    search_vector tsvector,
    
    -- Engagement metrics
    view_count INTEGER DEFAULT 0,
    like_count INTEGER DEFAULT 0,
    share_count INTEGER DEFAULT 0,
    
    -- Metadata
    metadata JSONB DEFAULT '{}',
    
    -- Timestamps
    created_at TIMESTAMPTZ DEFAULT NOW(),
    updated_at TIMESTAMPTZ DEFAULT NOW(),
    published_at TIMESTAMPTZ
);

-- Required indexes
CREATE INDEX idx_{feature_name}_content_user_id ON {feature_name}_content(user_id);
CREATE INDEX idx_{feature_name}_content_status ON {feature_name}_content(status);
CREATE INDEX idx_{feature_name}_content_published_at ON {feature_name}_content(published_at) WHERE published_at IS NOT NULL;
CREATE INDEX idx_{feature_name}_content_search ON {feature_name}_content USING gin(search_vector);
CREATE INDEX idx_{feature_name}_content_tags ON {feature_name}_content USING gin(tags);

-- Search vector trigger
CREATE TRIGGER {feature_name}_content_search_vector_update
    BEFORE INSERT OR UPDATE ON {feature_name}_content
    FOR EACH ROW EXECUTE FUNCTION 
    tsvector_update_trigger(search_vector, 'pg_catalog.english', title, content);
```

### Real-time Features (Chat, Notifications, etc.)
```sql
-- Template for real-time features
CREATE TABLE {feature_name}_messages (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    
    -- Participants
    sender_id UUID NOT NULL REFERENCES users(id) ON DELETE CASCADE,
    recipient_id UUID REFERENCES users(id) ON DELETE CASCADE,
    channel_id UUID,
    
    -- Message content
    message_type TEXT DEFAULT 'text' CHECK (message_type IN ('text', 'image', 'file', 'system')),
    content TEXT,
    
    -- Real-time status
    status TEXT DEFAULT 'sent' CHECK (status IN ('sent', 'delivered', 'read', 'failed')),
    delivered_at TIMESTAMPTZ,
    read_at TIMESTAMPTZ,
    
    -- Message metadata
    reply_to_id UUID REFERENCES {feature_name}_messages(id),
    edited BOOLEAN DEFAULT false,
    edited_at TIMESTAMPTZ,
    
    -- Cleanup helpers
    expires_at TIMESTAMPTZ,
    
    -- Timestamps
    created_at TIMESTAMPTZ DEFAULT NOW()
);

-- Indexes optimized for real-time queries
CREATE INDEX idx_{feature_name}_messages_recipient_created ON {feature_name}_messages(recipient_id, created_at);
CREATE INDEX idx_{feature_name}_messages_channel_created ON {feature_name}_messages(channel_id, created_at);
CREATE INDEX idx_{feature_name}_messages_expires_at ON {feature_name}_messages(expires_at) WHERE expires_at IS NOT NULL;

-- Auto-cleanup trigger for temporary messages
CREATE OR REPLACE FUNCTION cleanup_expired_{feature_name}_messages()
RETURNS TRIGGER AS $$
BEGIN
    DELETE FROM {feature_name}_messages 
    WHERE expires_at < NOW() 
    AND expires_at IS NOT NULL;
    RETURN NULL;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER cleanup_{feature_name}_messages_trigger
    AFTER INSERT ON {feature_name}_messages
    EXECUTE FUNCTION cleanup_expired_{feature_name}_messages();
```

## üîÑ Schema Versioning Strategy

### Version Control for Database Changes
```sql
-- Schema version tracking
CREATE TABLE schema_versions (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    version_number INTEGER NOT NULL UNIQUE,
    version_name TEXT NOT NULL,
    description TEXT,
    migration_script TEXT,
    rollback_script TEXT,
    applied_at TIMESTAMPTZ DEFAULT NOW(),
    applied_by TEXT DEFAULT current_user
);

-- Feature flags table for gradual rollouts
CREATE TABLE feature_flags (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    feature_name TEXT NOT NULL UNIQUE,
    enabled BOOLEAN DEFAULT false,
    rollout_percentage INTEGER DEFAULT 0 CHECK (rollout_percentage BETWEEN 0 AND 100),
    target_users TEXT[], -- Specific user IDs for testing
    created_at TIMESTAMPTZ DEFAULT NOW(),
    updated_at TIMESTAMPTZ DEFAULT NOW()
);
```

### Database Migration Framework
```javascript
// Migration management system
export class DatabaseMigration {
  static async getCurrentVersion() {
    const { data } = await supabase
      .from('schema_versions')
      .select('version_number')
      .order('version_number', { ascending: false })
      .limit(1);
    
    return data?.[0]?.version_number || 0;
  }

  static async applyMigration(migrationConfig) {
    const startTime = performance.now();
    
    try {
      // 1. Validate migration
      await this.validateMigration(migrationConfig);
      
      // 2. Create backup point
      await this.createBackupPoint(migrationConfig.version);
      
      // 3. Execute migration
      await this.executeMigration(migrationConfig);
      
      // 4. Verify migration success
      await this.verifyMigration(migrationConfig);
      
      // 5. Record migration
      await this.recordMigration(migrationConfig, startTime);
      
      logger.info(`Migration ${migrationConfig.version} completed successfully`);
      
    } catch (error) {
      logger.error(`Migration ${migrationConfig.version} failed:`, error);
      
      // Attempt rollback
      await this.rollbackMigration(migrationConfig);
      throw error;
    }
  }

  static async validateMigration(config) {
    // Check for breaking changes
    if (config.breakingChanges) {
      const activeConnections = await this.checkActiveConnections();
      if (activeConnections > 10) {
        throw new Error('Cannot apply breaking changes with active connections');
      }
    }

    // Validate SQL syntax
    await this.validateSQL(config.migrationScript);
    
    // Check rollback script
    await this.validateSQL(config.rollbackScript);
  }
}
```

## üìä Schema Health Monitoring

### Schema Validation Tools
```javascript
// Comprehensive schema validation
export async function validateSchemaHealth() {
  const issues = [];

  // 1. Check for missing foreign key indexes
  const missingFKIndexes = await checkMissingForeignKeyIndexes();
  if (missingFKIndexes.length > 0) {
    issues.push({
      type: 'performance',
      severity: 'high',
      description: 'Foreign keys without indexes detected',
      details: missingFKIndexes
    });
  }

  // 2. Check for unused indexes
  const unusedIndexes = await findUnusedIndexes();
  if (unusedIndexes.length > 0) {
    issues.push({
      type: 'storage',
      severity: 'medium', 
      description: 'Unused indexes consuming storage',
      details: unusedIndexes
    });
  }

  // 3. Check for tables without cleanup strategy
  const tablesWithoutCleanup = await findTablesWithoutCleanupStrategy();
  if (tablesWithoutCleanup.length > 0) {
    issues.push({
      type: 'maintenance',
      severity: 'high',
      description: 'Tables without data lifecycle management',
      details: tablesWithoutCleanup
    });
  }

  // 4. Check for schema drift
  const schemaDrift = await detectSchemaDrift();
  if (schemaDrift.length > 0) {
    issues.push({
      type: 'consistency',
      severity: 'critical',
      description: 'Schema inconsistencies detected',
      details: schemaDrift
    });
  }

  return issues;
}

async function detectSchemaDrift() {
  // Compare current schema with expected schema from complete_schema.sql
  const expectedSchema = await parseSchemaFile('lib/supabase/complete_schema.sql');
  const currentSchema = await getCurrentDatabaseSchema();
  
  return compareSchemas(expectedSchema, currentSchema);
}
```

## üö® Feature Development Safety Rules

### Pre-Development Checklist
```javascript
const featureDevelopmentChecklist = {
  planning: [
    'Define data models and relationships',
    'Plan migration strategy', 
    'Design cleanup and archival procedures',
    'Estimate performance impact',
    'Plan testing approach'
  ],
  
  development: [
    'Update schema documentation',
    'Create migration scripts',
    'Add appropriate indexes',
    'Implement data validation',
    'Add performance monitoring'
  ],
  
  testing: [
    'Test migrations on staging',
    'Validate data integrity',
    'Test rollback procedures',
    'Performance benchmark',
    'Load testing with realistic data'
  ],
  
  deployment: [
    'Create backup before migration',
    'Apply migration during low traffic',
    'Monitor performance impact',
    'Verify feature functionality',
    'Enable gradual rollout'
  ]
};
```

### Feature Gate Implementation
```sql
-- Feature gates for controlled rollouts
CREATE TABLE feature_gates (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    feature_name TEXT NOT NULL UNIQUE,
    enabled_globally BOOLEAN DEFAULT false,
    
    -- Rollout controls
    rollout_percentage INTEGER DEFAULT 0,
    user_whitelist UUID[],
    business_whitelist UUID[],
    
    -- Conditions
    min_user_tier TEXT,
    required_subscription TEXT,
    
    -- Metadata
    description TEXT,
    created_at TIMESTAMPTZ DEFAULT NOW(),
    updated_at TIMESTAMPTZ DEFAULT NOW()
);

-- Function to check feature access
CREATE OR REPLACE FUNCTION user_has_feature_access(
    user_id UUID,
    feature_name TEXT
) RETURNS BOOLEAN AS $$
DECLARE
    gate RECORD;
    user_hash INTEGER;
BEGIN
    SELECT * INTO gate FROM feature_gates WHERE feature_gates.feature_name = user_has_feature_access.feature_name;
    
    IF NOT FOUND THEN
        RETURN false;
    END IF;
    
    -- Global enable/disable
    IF gate.enabled_globally THEN
        RETURN true;
    END IF;
    
    -- Whitelist check
    IF user_id = ANY(gate.user_whitelist) THEN
        RETURN true;
    END IF;
    
    -- Percentage rollout
    IF gate.rollout_percentage > 0 THEN
        user_hash := hashtext(user_id::TEXT) % 100;
        IF user_hash < gate.rollout_percentage THEN
            RETURN true;
        END IF;
    END IF;
    
    RETURN false;
END;
$$ LANGUAGE plpgsql;
```

## üí° Schema Evolution Best Practices

### DO:
- Plan data lifecycle before creating tables
- Use feature flags for gradual rollouts
- Always create rollback procedures
- Test migrations on staging with production data size
- Monitor performance impact of schema changes
- Document all schema changes thoroughly
- Use backwards-compatible migrations when possible
- Implement proper indexing strategy from the start

### DON'T:
- Add columns without considering cleanup strategy
- Make breaking changes without migration plan
- Skip performance testing for new features
- Deploy schema changes without rollback plan
- Ignore foreign key constraints
- Create tables without standard columns (id, created_at, updated_at)
- Add features without considering data growth

### Schema Health Metrics:
- Schema drift detection
- Missing index alerts  
- Unused table/column monitoring
- Data growth rate tracking
- Query performance degradation alerts
- Foreign key constraint violations

**Remember: Good schema evolution prevents technical debt. Plan for the future, but ship incrementally.**